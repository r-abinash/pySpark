{
 "cells": [
  {
   "cell_type": "raw",
   "id": "94abe53f-2196-46f8-b611-e841113b8da8",
   "metadata": {},
   "source": [
    "Topics to cover:\n",
    "    PySpark Dataframe\n",
    "    Reading The Dataset\n",
    "    Checking the Datatypes of the Column(Schema)\n",
    "    Selecting Columns And Indexing\n",
    "    Check Describe option similar to Pandas\n",
    "    Adding Columns\n",
    "    Dropping columns\n",
    "    rename columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ecb88b76-6480-4061-8142-3d9bd9118db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9f1f78a9-6ff5-4299-b621-7c1249fc8df0",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName('DataFrame part1').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "90e2ef34-fa14-49a4-b300-24c6bfc8c2d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://LAPTOP-45GRI7QD:4041\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.4</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>DataFrame part1</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x1f887a6c6d0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2acc9a22-ceb6-4565-8c2e-01a93784daa6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[Name: string, Age: string, Experience: string]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# type1 - read dataset\n",
    "df_spark = spark.read.option('header','true').csv('test1.csv')\n",
    "df_spark \n",
    "# even though the actual column age and experience are in integer but here it shown as string.\n",
    "# Because bydefault all cloumn are consider as string.\n",
    "# To make it as orginal use parameter \"inferSchema=True\" in csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d67677c6-fa73-4f62-9a6e-f68448f48963",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+---+----------+\n",
      "|        Name|Age|Experience|\n",
      "+------------+---+----------+\n",
      "|     Abinash| 21|         3|\n",
      "|Rajapandiyan| 45|         4|\n",
      "|    Amsaveni| 43|         5|\n",
      "|       Thiya| 22|         1|\n",
      "|     Abinesh| 21|         4|\n",
      "|     Adhavan| 20|         9|\n",
      "|        Adhi| 15|         5|\n",
      "+------------+---+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_spark.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d845f0e1-ace9-4184-bd43-0dafe254227b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[Name: string, Age: int, Experience: int]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use 'inferSchema=True'\n",
    "df_spark = spark.read.option('header','true').csv('test1.csv',inferSchema=True)\n",
    "df_spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1864aa96-9e5e-46a4-b391-a3e549b785ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+---+----------+\n",
      "|        Name|Age|Experience|\n",
      "+------------+---+----------+\n",
      "|     Abinash| 21|         3|\n",
      "|Rajapandiyan| 45|         4|\n",
      "|    Amsaveni| 43|         5|\n",
      "|       Thiya| 22|         1|\n",
      "|     Abinesh| 21|         4|\n",
      "|     Adhavan| 20|         9|\n",
      "|        Adhi| 15|         5|\n",
      "+------------+---+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_spark.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ff37cf75-a758-42f0-9d0c-e9ac4c941bed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Name: string (nullable = true)\n",
      " |-- Age: integer (nullable = true)\n",
      " |-- Experience: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# check schema\n",
    "df_spark.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "db825dde-e1f0-4e50-bb34-b3f1153c3286",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+---+----------+\n",
      "|        Name|Age|Experience|\n",
      "+------------+---+----------+\n",
      "|     Abinash| 21|         3|\n",
      "|Rajapandiyan| 45|         4|\n",
      "|    Amsaveni| 43|         5|\n",
      "|       Thiya| 22|         1|\n",
      "|     Abinesh| 21|         4|\n",
      "|     Adhavan| 20|         9|\n",
      "|        Adhi| 15|         5|\n",
      "+------------+---+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# type2 - read dataset\n",
    "df_spark = spark.read.csv('test1.csv',header=True,inferSchema=True)\n",
    "df_spark.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "722c9fe2-e2c3-4681-be92-55930b483457",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Name: string (nullable = true)\n",
      " |-- Age: integer (nullable = true)\n",
      " |-- Experience: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# check schema\n",
    "df_spark.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "02c89d87-4078-4c7c-8d7a-f64964b057a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df_spark) # Dataframe is a 2-dimensional, tabular data structure. Inside it we can perform varies kind of operation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "72b19d64-02e2-4aa0-a7f5-c9043473dd82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Name', 'Age', 'Experience']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show the row names\n",
    "df_spark.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7c4d6a5e-47b0-4e93-abfe-e0c06fa604d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(Name='Abinash', Age=21, Experience=3),\n",
       " Row(Name='Rajapandiyan', Age=45, Experience=4),\n",
       " Row(Name='Amsaveni', Age=43, Experience=5)]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get head of the tabel\n",
    "df_spark.head(3) # return frst 3 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d1dfaa51-cf2f-4078-ba02-0a3e309ccd91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+---+----------+\n",
      "|        Name|Age|Experience|\n",
      "+------------+---+----------+\n",
      "|     Abinash| 21|         3|\n",
      "|Rajapandiyan| 45|         4|\n",
      "|    Amsaveni| 43|         5|\n",
      "|       Thiya| 22|         1|\n",
      "|     Abinesh| 21|         4|\n",
      "|     Adhavan| 20|         9|\n",
      "|        Adhi| 15|         5|\n",
      "+------------+---+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_spark.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d0dfc017-72ad-4823-a700-8ce9243740e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[Name: string]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#select by column\n",
    "df_spark.select('Name') # pass the column name. Return the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7e942f75-387f-4394-89dd-6041d368e993",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+\n",
      "|        Name|\n",
      "+------------+\n",
      "|     Abinash|\n",
      "|Rajapandiyan|\n",
      "|    Amsaveni|\n",
      "|       Thiya|\n",
      "|     Abinesh|\n",
      "|     Adhavan|\n",
      "|        Adhi|\n",
      "+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_spark.select('Name').show() # return the particular column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "85ab7886-5859-4f99-a9ad-e65b9cf4baa9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[Name: string, Experience: int]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# if we wants to select multiple columns. pass the column names through list\n",
    "df_spark.select(['Name','Experience'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d05d5957-56c6-4b31-bc08-d1c9d798f160",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+----------+\n",
      "|        Name|Experience|\n",
      "+------------+----------+\n",
      "|     Abinash|         3|\n",
      "|Rajapandiyan|         4|\n",
      "|    Amsaveni|         5|\n",
      "|       Thiya|         1|\n",
      "|     Abinesh|         4|\n",
      "|     Adhavan|         9|\n",
      "|        Adhi|         5|\n",
      "+------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_spark.select(['Name','Experience']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f97c315f-e747-46f6-a206-2e39df97d609",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Name', 'string'), ('Age', 'int'), ('Experience', 'int')]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# types of column\n",
    "df_spark.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "782d3da3-8e6a-4804-8dd2-3a03dac536ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[summary: string, Name: string, Age: string, Experience: string]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# describe -> gives the overall information of the table..calculates like mean,std, etc... eventhough the column is string \n",
    "df_spark.describe() # return as string for all columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b2114b7e-0ed2-49b4-a537-bf28074dfafb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+------------------+-----------------+\n",
      "|summary|   Name|               Age|       Experience|\n",
      "+-------+-------+------------------+-----------------+\n",
      "|  count|      7|                 7|                7|\n",
      "|   mean|   NULL|26.714285714285715|4.428571428571429|\n",
      "| stddev|   NULL|12.037639382568408|2.439750182371333|\n",
      "|    min|Abinash|                15|                1|\n",
      "|    max|  Thiya|                45|                9|\n",
      "+-------+-------+------------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_spark.describe().show() # min,max for string is based on index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ef5ba04e-f27a-4616-a41c-b6bff5947c24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+---+----------+------------------------+\n",
      "|        Name|Age|Experience|Experience after 2 years|\n",
      "+------------+---+----------+------------------------+\n",
      "|     Abinash| 21|         3|                       5|\n",
      "|Rajapandiyan| 45|         4|                       6|\n",
      "|    Amsaveni| 43|         5|                       7|\n",
      "|       Thiya| 22|         1|                       3|\n",
      "|     Abinesh| 21|         4|                       6|\n",
      "|     Adhavan| 20|         9|                      11|\n",
      "|        Adhi| 15|         5|                       7|\n",
      "+------------+---+----------+------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_spark=df_spark.withColumn('Experience after 2 years',df_spark['Experience']+2)\n",
    "df_spark.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d7859118-c7bd-40fa-ab05-2184065fd865",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+---+----------+\n",
      "|        Name|Age|Experience|\n",
      "+------------+---+----------+\n",
      "|     Abinash| 21|         3|\n",
      "|Rajapandiyan| 45|         4|\n",
      "|    Amsaveni| 43|         5|\n",
      "|       Thiya| 22|         1|\n",
      "|     Abinesh| 21|         4|\n",
      "|     Adhavan| 20|         9|\n",
      "|        Adhi| 15|         5|\n",
      "+------------+---+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_spark.drop('Experience after 2 years').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e4285c45-49df-46ff-88ef-8171f13b821c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+---+----------+------------------------+\n",
      "|        Name|Age|Experience|Experience after 2 years|\n",
      "+------------+---+----------+------------------------+\n",
      "|     Abinash| 21|         3|                       5|\n",
      "|Rajapandiyan| 45|         4|                       6|\n",
      "|    Amsaveni| 43|         5|                       7|\n",
      "|       Thiya| 22|         1|                       3|\n",
      "|     Abinesh| 21|         4|                       6|\n",
      "|     Adhavan| 20|         9|                      11|\n",
      "|        Adhi| 15|         5|                       7|\n",
      "+------------+---+----------+------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_spark.show() # column operations are immutable .we can see the changes by reassign it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "0c823637-aae6-470d-b5a4-3889d6b867c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+---+----------+\n",
      "|        Name|Age|Experience|\n",
      "+------------+---+----------+\n",
      "|     Abinash| 21|         3|\n",
      "|Rajapandiyan| 45|         4|\n",
      "|    Amsaveni| 43|         5|\n",
      "|       Thiya| 22|         1|\n",
      "|     Abinesh| 21|         4|\n",
      "|     Adhavan| 20|         9|\n",
      "|        Adhi| 15|         5|\n",
      "+------------+---+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_spark=df_spark.drop('Experience after 2 years')\n",
    "df_spark.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "a8b3d7ca-e576-479d-a359-7957eaa5dc6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+---+----------+\n",
      "|    New Name|Age|Experience|\n",
      "+------------+---+----------+\n",
      "|     Abinash| 21|         3|\n",
      "|Rajapandiyan| 45|         4|\n",
      "|    Amsaveni| 43|         5|\n",
      "|       Thiya| 22|         1|\n",
      "|     Abinesh| 21|         4|\n",
      "|     Adhavan| 20|         9|\n",
      "|        Adhi| 15|         5|\n",
      "+------------+---+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_spark.withColumnRenamed('Name','New Name').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1027f2d8-0371-4a98-b60a-96adc74050dd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
