{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e16e127-700a-403b-b988-54b91ded1c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "07c4f789-0f83-437b-b8ef-33de9d57f05d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e7941d75-e5fb-43e3-a733-ec3bbd0e58d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Abinash</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Rajapandiyan</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Amsaveni</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Thiya</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Abinesh</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Adhavan</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Adhi</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Name  Age\n",
       "0       Abinash   21\n",
       "1  Rajapandiyan   45\n",
       "2      Amsaveni   43\n",
       "3         Thiya   22\n",
       "4       Abinesh   21\n",
       "5       Adhavan   20\n",
       "6          Adhi   15"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv('test1.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f308fb50-621e-426f-b8fa-c2f9a603c007",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df) # it is pandas dataframe."
   ]
  },
  {
   "cell_type": "raw",
   "id": "9481e5ed-420f-4c20-a02a-43fa1c0f558a",
   "metadata": {},
   "source": [
    "when i really want to work with pyspark, we need to start a spark session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "99db3251-1c31-4edc-89ff-786d819af6c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bbc6da43-bdb3-400e-969d-5a25508e13c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName('Parctice').getOrCreate() # this will create sparksession and we set name for it as 'Practice'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "42339ea8-176d-4501-b217-135e36aaaa23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://LAPTOP-45GRI7QD:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.4</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Parctice</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x28e0295ecb0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "010076fd-dab3-4120-a519-b2bc9a35c9ed",
   "metadata": {},
   "source": [
    "when u execute on local there always one cluster -> master points to 'local'\n",
    "But when u are actually working with cloud we can create multiple cluster and instance -> master have like cluster structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2e059adc-6636-4e43-b450-ccce93120ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pyspark = spark.read.csv('test1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6ecc9c63-3b12-486d-ae3e-9bec712be0e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[_c0: string, _c1: string]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pyspark # here by default column name is consider as c0,c1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "43cd4ee7-7f6e-4b94-a21e-4f98fa7d7207",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+---+\n",
      "|         _c0|_c1|\n",
      "+------------+---+\n",
      "|        Name|Age|\n",
      "|     Abinash| 21|\n",
      "|Rajapandiyan| 45|\n",
      "|    Amsaveni| 43|\n",
      "|       Thiya| 22|\n",
      "|     Abinesh| 21|\n",
      "|     Adhavan| 20|\n",
      "|        Adhi| 15|\n",
      "+------------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d8a883b7-b388-4105-98b3-2e9b705797c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[Name: string, Age: string]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# but we wants the actual column name whats we gives.\n",
    "df_pyspark = spark.read.option('header','true').csv('test1.csv') #whatever in the frst row that is consider as 'header'.\n",
    "df_pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ffe6c8e8-8796-46f7-9eb7-1bab7c3f449d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+---+\n",
      "|        Name|Age|\n",
      "+------------+---+\n",
      "|     Abinash| 21|\n",
      "|Rajapandiyan| 45|\n",
      "|    Amsaveni| 43|\n",
      "|       Thiya| 22|\n",
      "|     Abinesh| 21|\n",
      "|     Adhavan| 20|\n",
      "|        Adhi| 15|\n",
      "+------------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d38ec682-202c-452e-8e96-ed1de90e1474",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df_pyspark) # it is sql dataframe.here most of the API's have some same functions that do the similar jobs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e1349808-5558-4d55-8f80-7229fd591d15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(Name='Abinash', Age='21'),\n",
       " Row(Name='Rajapandiyan', Age='45'),\n",
       " Row(Name='Amsaveni', Age='43'),\n",
       " Row(Name='Thiya', Age='22')]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pyspark.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "13f5f583-12b8-4a7f-9594-0fb8bc5261d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Name: string (nullable = true)\n",
      " |-- Age: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.printSchema() #look like \"df.info()\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9676c346-e10b-4408-9a46-b376985f4a93",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "add91493-673a-40df-bb41-a49520443544",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d54fc23-372d-492e-a94b-77c20383b69b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe131a10-68b6-4caf-a118-6b2c2ef300ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bac5fb2c-405c-4e8b-8033-f79a0a38f791",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37ea54d7-0ef4-4fec-a3db-5084bb0719c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72579078-c70e-4d77-a3f9-b59b0b3fe1be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f2198ed-9083-4fa1-b0a2-80447f237341",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e077742-1bc4-4b7c-a9df-7c8fdbf5a8f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc4f951b-0bb1-4f09-acfa-4327c38b72d0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
