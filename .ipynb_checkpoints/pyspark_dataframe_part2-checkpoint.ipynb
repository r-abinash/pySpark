{
 "cells": [
  {
   "cell_type": "raw",
   "id": "358f3c4d-4135-4166-a7e5-bcc3870e04fc",
   "metadata": {},
   "source": [
    "Pyspark Handling Missing Values:\n",
    "    Dropping Columns\n",
    "    Dropping Rows\n",
    "    Various Parameter In Dropping functionalities\n",
    "    Handling Missing values by Mean, Median And Mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "88a31443-b8cb-44e2-8900-f3f6d34e9c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "47470aeb-565c-446a-9c4b-4a5cab4b9762",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName('Dataframe part2').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a1cea8d8-7c39-4ed9-abc6-8c240a209eca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://LAPTOP-45GRI7QD:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.4</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Dataframe part2</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x1fc8956c1c0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e2e280ac-316c-495c-907f-87b90b0a7c94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[Name: string, Age: int, Experience (Years): int, Salary: int]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = spark.read.csv('employee_data.csv',header=True,inferSchema=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "545c1003-c758-4088-a639-7a07e9100174",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----+------------------+------+\n",
      "|     Name| Age|Experience (Years)|Salary|\n",
      "+---------+----+------------------+------+\n",
      "|    Krish|  31|                10| 30000|\n",
      "|Sudhanshi|  30|                 8| 25000|\n",
      "|    Sunny|  29|                 4| 20000|\n",
      "|     Paul|  24|                 3| 20000|\n",
      "|   Harsha|  21|                 1| 15000|\n",
      "|  Shubham|  23|                 2| 18000|\n",
      "|   Mahesh|NULL|              NULL| 38000|\n",
      "|     NULL|  34|                10|  NULL|\n",
      "|     NULL|  36|              NULL|  NULL|\n",
      "+---------+----+------------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6b33df90-ed82-4f82-be58-c66925abd856",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+------------------+------+\n",
      "| Age|Experience (Years)|Salary|\n",
      "+----+------------------+------+\n",
      "|  31|                10| 30000|\n",
      "|  30|                 8| 25000|\n",
      "|  29|                 4| 20000|\n",
      "|  24|                 3| 20000|\n",
      "|  21|                 1| 15000|\n",
      "|  23|                 2| 18000|\n",
      "|NULL|              NULL| 38000|\n",
      "|  34|                10|  NULL|\n",
      "|  36|              NULL|  NULL|\n",
      "+----+------------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# drop column\n",
    "df.drop('Name').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c131630e-7e0a-4d5e-938f-85874cf03973",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---+------------------+------+\n",
      "|     Name|Age|Experience (Years)|Salary|\n",
      "+---------+---+------------------+------+\n",
      "|    Krish| 31|                10| 30000|\n",
      "|Sudhanshi| 30|                 8| 25000|\n",
      "|    Sunny| 29|                 4| 20000|\n",
      "|     Paul| 24|                 3| 20000|\n",
      "|   Harsha| 21|                 1| 15000|\n",
      "|  Shubham| 23|                 2| 18000|\n",
      "+---------+---+------------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.na.drop().show() # this will remove rows where 'null' take place.\n",
    "# In drop function -> how,thersh,subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3e29ff0e-0494-4f49-b8d8-48c3e875a286",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---+------------------+------+\n",
      "|     Name|Age|Experience (Years)|Salary|\n",
      "+---------+---+------------------+------+\n",
      "|    Krish| 31|                10| 30000|\n",
      "|Sudhanshi| 30|                 8| 25000|\n",
      "|    Sunny| 29|                 4| 20000|\n",
      "|     Paul| 24|                 3| 20000|\n",
      "|   Harsha| 21|                 1| 15000|\n",
      "|  Shubham| 23|                 2| 18000|\n",
      "+---------+---+------------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 1 -> how\n",
    "df.na.drop(how='any').show() # by default how = any ->even one null in row meant it will drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "72826b01-8939-492c-8695-88f9b0997f63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----+------------------+------+\n",
      "|     Name| Age|Experience (Years)|Salary|\n",
      "+---------+----+------------------+------+\n",
      "|    Krish|  31|                10| 30000|\n",
      "|Sudhanshi|  30|                 8| 25000|\n",
      "|    Sunny|  29|                 4| 20000|\n",
      "|     Paul|  24|                 3| 20000|\n",
      "|   Harsha|  21|                 1| 15000|\n",
      "|  Shubham|  23|                 2| 18000|\n",
      "|   Mahesh|NULL|              NULL| 38000|\n",
      "|     NULL|  34|                10|  NULL|\n",
      "|     NULL|  36|              NULL|  NULL|\n",
      "+---------+----+------------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.na.drop(how='all').show()# how = all -> if row have all as null meant it will drop.in our case there is no row like that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3720f57a-fc74-471e-b05a-d32b893f631b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----+------------------+------+\n",
      "|     Name| Age|Experience (Years)|Salary|\n",
      "+---------+----+------------------+------+\n",
      "|    Krish|  31|                10| 30000|\n",
      "|Sudhanshi|  30|                 8| 25000|\n",
      "|    Sunny|  29|                 4| 20000|\n",
      "|     Paul|  24|                 3| 20000|\n",
      "|   Harsha|  21|                 1| 15000|\n",
      "|  Shubham|  23|                 2| 18000|\n",
      "|   Mahesh|NULL|              NULL| 38000|\n",
      "|     NULL|  34|                10|  NULL|\n",
      "+---------+----+------------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 2 -> thersh\n",
    "df.na.drop(how='any',thresh=2).show() # we set threshold value as 2.It tells that each row should have atleast 2 non null value. If not meant drop it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dfe7c6c4-cfb7-4521-8475-3e8c50c04e04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---+------------------+------+\n",
      "|     Name|Age|Experience (Years)|Salary|\n",
      "+---------+---+------------------+------+\n",
      "|    Krish| 31|                10| 30000|\n",
      "|Sudhanshi| 30|                 8| 25000|\n",
      "|    Sunny| 29|                 4| 20000|\n",
      "|     Paul| 24|                 3| 20000|\n",
      "|   Harsha| 21|                 1| 15000|\n",
      "|  Shubham| 23|                 2| 18000|\n",
      "|     NULL| 34|                10|  NULL|\n",
      "+---------+---+------------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 3 -> subset\n",
    "df.na.drop(how='any',subset=['Experience (Years)']).show() # if we want to drop null values only for specific column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "34a8a92a-bb34-431f-851b-29e86fe04dc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----+------------------+------+\n",
      "|     Name| Age|Experience (Years)|Salary|\n",
      "+---------+----+------------------+------+\n",
      "|    Krish|  31|                10| 30000|\n",
      "|Sudhanshi|  30|                 8| 25000|\n",
      "|    Sunny|  29|                 4| 20000|\n",
      "|     Paul|  24|                 3| 20000|\n",
      "|   Harsha|  21|                 1| 15000|\n",
      "|  Shubham|  23|                 2| 18000|\n",
      "|   Mahesh|NULL|              NULL| 38000|\n",
      "+---------+----+------------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.na.drop(how='any',subset=['Name','Salary']).show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4121bb7f-03f2-4f9d-9966-51c0dde3d255",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----+------------------+------+\n",
      "|     Name| Age|Experience (Years)|Salary|\n",
      "+---------+----+------------------+------+\n",
      "|    Krish|  31|                10| 30000|\n",
      "|Sudhanshi|  30|                 8| 25000|\n",
      "|    Sunny|  29|                 4| 20000|\n",
      "|     Paul|  24|                 3| 20000|\n",
      "|   Harsha|  21|                 1| 15000|\n",
      "|  Shubham|  23|                 2| 18000|\n",
      "|   Mahesh|NULL|              NULL| 38000|\n",
      "|      hai|  34|                10|  NULL|\n",
      "|      hai|  36|              NULL|  NULL|\n",
      "+---------+----+------------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Fill the missing values\n",
    "df.na.fill(value='hai').show() # now in value we pass string 'hai'.so it fill with 'hai' where string column have null."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3c8e68ed-5387-4492-bfcf-8da477b873ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+------------------+---------+\n",
      "|     Name|      Age|Experience (Years)|   Salary|\n",
      "+---------+---------+------------------+---------+\n",
      "|    Krish|       31|                10|    30000|\n",
      "|Sudhanshi|       30|                 8|    25000|\n",
      "|    Sunny|       29|                 4|    20000|\n",
      "|     Paul|       24|                 3|    20000|\n",
      "|   Harsha|       21|                 1|    15000|\n",
      "|  Shubham|       23|                 2|    18000|\n",
      "|   Mahesh|999999999|         999999999|    38000|\n",
      "|     NULL|       34|                10|999999999|\n",
      "|     NULL|       36|         999999999|999999999|\n",
      "+---------+---------+------------------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.na.fill(value=999999999).show()# now we pass int so.it see int type columns have null and fill them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ab3b4ea2-28b2-4a0a-ab25-bd2eb2433006",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+------------------+---------+\n",
      "|     Name|      Age|Experience (Years)|   Salary|\n",
      "+---------+---------+------------------+---------+\n",
      "|    Krish|       31|                10|    30000|\n",
      "|Sudhanshi|       30|                 8|    25000|\n",
      "|    Sunny|       29|                 4|    20000|\n",
      "|     Paul|       24|                 3|    20000|\n",
      "|   Harsha|       21|                 1|    15000|\n",
      "|  Shubham|       23|                 2|    18000|\n",
      "|   Mahesh|999999999|              NULL|    38000|\n",
      "|     NULL|       34|                10|999999999|\n",
      "|     NULL|       36|              NULL|999999999|\n",
      "+---------+---------+------------------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.na.fill(value=999999999,subset=['Age','Salary']).show() # we can also specify the column also by using subset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "62008a76-6491-47a7-a17a-6798ac4c8666",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can also fill the null values by their respective column mean,median,std....values etc..\n",
    "# For that we us 'imputer' ->  it is works for only numeric columns.\n",
    "from pyspark.ml.feature import Imputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6a526b96-6d50-47ce-b9d5-4ef6acfdb4fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer = Imputer(\n",
    "    inputCols=['Age','Experience (Years)','Salary'],\n",
    "    outputCols=['{}_imputer'.format(c) for c in ['Age','Experience (Years)','Salary']]\n",
    ").setStrategy('mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e048de05-7e2d-4725-ba9a-0647a90f594c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----+------------------+------+-----------+--------------------------+--------------+\n",
      "|     Name| Age|Experience (Years)|Salary|Age_imputer|Experience (Years)_imputer|Salary_imputer|\n",
      "+---------+----+------------------+------+-----------+--------------------------+--------------+\n",
      "|    Krish|  31|                10| 30000|         31|                        10|         30000|\n",
      "|Sudhanshi|  30|                 8| 25000|         30|                         8|         25000|\n",
      "|    Sunny|  29|                 4| 20000|         29|                         4|         20000|\n",
      "|     Paul|  24|                 3| 20000|         24|                         3|         20000|\n",
      "|   Harsha|  21|                 1| 15000|         21|                         1|         15000|\n",
      "|  Shubham|  23|                 2| 18000|         23|                         2|         18000|\n",
      "|   Mahesh|NULL|              NULL| 38000|         28|                         5|         38000|\n",
      "|     NULL|  34|                10|  NULL|         34|                        10|         23714|\n",
      "|     NULL|  36|              NULL|  NULL|         36|                         5|         23714|\n",
      "+---------+----+------------------+------+-----------+--------------------------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# them fit and transform imputer columns with df.\n",
    "imputer.fit(df).transform(df).show() # its give imputer colum + excisting dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36c15114-a2b9-465b-935a-c27401bc2120",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
